{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\abala\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\users\\abala\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "c:\\users\\abala\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('preprocessedDataset.csv')\n",
    "df.head()\n",
    "df = df.dropna()\n",
    "df['speaker'] = df['speaker'].astype('str')\n",
    "df['response'] = df['response'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createSpeakerSet(text):\n",
    "    global promptSet\n",
    "    global promptDict\n",
    "    \n",
    "    text = str(text)\n",
    "    for word in text.split(' '):\n",
    "        if word in promptDict:\n",
    "            promptDict[word] = promptDict[word] + 1\n",
    "            if promptDict[word] > 4:\n",
    "                promptSet.add(word)\n",
    "        else:\n",
    "            promptDict[word] = 1\n",
    "        \n",
    "def createResponseSet(text):\n",
    "    global respnseSet\n",
    "    global reponseDict\n",
    "    \n",
    "    text = str(text)\n",
    "    for word in text.split(' '):\n",
    "        if word in responseDict:\n",
    "            responseDict[word] = responseDict[word] + 1\n",
    "            if responseDict[word] > 4:\n",
    "                responseSet.add(word)\n",
    "        else:\n",
    "            responseDict[word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "promptDict = {}\n",
    "responseDict = {}\n",
    "\n",
    "promptSet = set()\n",
    "responseSet = set()\n",
    "\n",
    "## add the end of the line word\n",
    "promptSet.add(\"<END>\")\n",
    "responseSet.add(\"<END>\")\n",
    "\n",
    "## add the word not in vocab word\n",
    "promptSet.add(\"<OTHER>\")\n",
    "responseSet.add(\"<OTHER>\")\n",
    "\n",
    "\n",
    "## create a set of the vocab for the speaker and the response\n",
    "_ = df['speaker'].apply(createSpeakerSet)\n",
    "_ = df['response'].apply(createResponseSet)\n",
    "\n",
    "## create the sorted vocabulary\n",
    "promptVocab = sorted(list(promptSet))\n",
    "responseVocab = sorted(list(promptSet))\n",
    "\n",
    "## get the size of the vocab\n",
    "promptVocabSize = len(promptVocab)\n",
    "responseVocabSize = len(responseVocab)\n",
    "\n",
    "## get the longest prompt and response\n",
    "#maxLenPrompt = max([len(str(txt)) for txt in list(df['speaker'])])\n",
    "maxLenPrompt = 50 + 1\n",
    "#maxLenResponse = max([len(str(txt)) for txt in list(df['response'])])\n",
    "maxLenResponse = 50 + 1\n",
    "\n",
    "## create the empty input and output vectors\n",
    "encoderInputSize = (len(df), maxLenPrompt, promptVocabSize)\n",
    "encoder_input = np.zeros(encoderInputSize, dtype = \"float32\")\n",
    "\n",
    "decoderInputSize = (len(df), maxLenResponse, responseVocabSize)\n",
    "decoder_input = np.zeros(decoderInputSize, dtype = \"float32\")\n",
    "\n",
    "decoder_output = np.zeros(decoderInputSize, dtype = \"float32\")\n",
    "\n",
    "## populate the empty input and output vectors\n",
    "inputText = list(df['speaker'])\n",
    "outputText = list(df['response'])\n",
    "\n",
    "for i, (i_t, o_t) in enumerate(zip(inputText, outputText)):\n",
    "    #print(inputText[i])\n",
    "    inputList = inputText[i].split(' ')\n",
    "    outputList = outputText[i].split(' ')\n",
    "    endInd = len(inputList)\n",
    "    if endInd > maxLenPrompt - 1:\n",
    "        endInd = maxLenPrompt - 1  \n",
    "    for x in range(endInd):\n",
    "        if inputList[x] in promptVocab:\n",
    "            ind = promptVocab.index(inputList[x])\n",
    "        else:\n",
    "            ind = promptVocab.index(\"<OTHER>\")\n",
    "        encoder_input[i][x][ind] = 1.0\n",
    "    encoder_input[i][x+1][promptVocab.index(\"<END>\")] = 1.0\n",
    "    endInd = len(outputList)\n",
    "    if endInd > maxLenResponse - 1:\n",
    "        endInd = maxLenResponse - 1\n",
    "    for x in range(endInd):\n",
    "        if outputList[x] in responseVocab:\n",
    "            ind = responseVocab.index(outputList[x])\n",
    "        else:\n",
    "            ind = responseVocab.index(\"<OTHER>\")\n",
    "        decoder_input[i][x][ind] = 1.0\n",
    "        if i >=1:\n",
    "            decoder_output[i][x-1][ind] = 1.0\n",
    "    decoder_input[i][x+1][responseVocab.index(\"<END>\")] = 1.0\n",
    "    decoder_output[i][x][responseVocab.index(\"<END>\")] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = keras.Input(shape = (None, promptVocabSize))\n",
    "encoder = keras.layers.LSTM(256, return_state = True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "decoder_inputs = keras.Input(shape = (None, responseVocabSize))\n",
    "\n",
    "decoder_lstm = keras.layers.LSTM(256, return_sequences = True, return_state = True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state = encoder_states)\n",
    "decoder_dense = keras.layers.Dense(responseVocabSize, activation = \"softmax\")\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "305/305 [==============================] - 560s 2s/step - loss: 1.5820 - accuracy: 0.0521\n",
      "Epoch 2/50\n",
      "305/305 [==============================] - 558s 2s/step - loss: 1.5814 - accuracy: 0.0521\n",
      "Epoch 3/50\n",
      "305/305 [==============================] - 438s 1s/step - loss: 1.5815 - accuracy: 0.0521\n",
      "Epoch 4/50\n",
      "305/305 [==============================] - 404s 1s/step - loss: 1.5813 - accuracy: 0.0521\n",
      "Epoch 5/50\n",
      "305/305 [==============================] - 400s 1s/step - loss: 1.5798 - accuracy: 0.0521\n",
      "Epoch 6/50\n",
      "305/305 [==============================] - 397s 1s/step - loss: 1.5807 - accuracy: 0.0521\n",
      "Epoch 7/50\n",
      "305/305 [==============================] - 403s 1s/step - loss: 1.5967 - accuracy: 0.0519\n",
      "Epoch 8/50\n",
      "305/305 [==============================] - 404s 1s/step - loss: 1.5839 - accuracy: 0.0520\n",
      "Epoch 9/50\n",
      "305/305 [==============================] - 426s 1s/step - loss: 1.5808 - accuracy: 0.0521\n",
      "Epoch 10/50\n",
      "305/305 [==============================] - 410s 1s/step - loss: 1.5814 - accuracy: 0.0521\n",
      "Epoch 11/50\n",
      "305/305 [==============================] - 423s 1s/step - loss: 1.5804 - accuracy: 0.0521\n",
      "Epoch 12/50\n",
      "305/305 [==============================] - 411s 1s/step - loss: 1.5798 - accuracy: 0.0522\n",
      "Epoch 13/50\n",
      "305/305 [==============================] - 400s 1s/step - loss: 1.5807 - accuracy: 0.0523\n",
      "Epoch 14/50\n",
      "305/305 [==============================] - 406s 1s/step - loss: 1.5781 - accuracy: 0.0523\n",
      "Epoch 15/50\n",
      "305/305 [==============================] - 403s 1s/step - loss: 1.5786 - accuracy: 0.0525\n",
      "Epoch 16/50\n",
      "305/305 [==============================] - 400s 1s/step - loss: 1.5789 - accuracy: 0.0526\n",
      "Epoch 17/50\n",
      "305/305 [==============================] - 405s 1s/step - loss: 1.5863 - accuracy: 0.0523\n",
      "Epoch 18/50\n",
      "305/305 [==============================] - 405s 1s/step - loss: 1.5789 - accuracy: 0.0528\n",
      "Epoch 19/50\n",
      "305/305 [==============================] - 406s 1s/step - loss: 1.5783 - accuracy: 0.0528\n",
      "Epoch 20/50\n",
      "305/305 [==============================] - 398s 1s/step - loss: 1.5783 - accuracy: 0.0529\n",
      "Epoch 21/50\n",
      "305/305 [==============================] - 398s 1s/step - loss: 1.5771 - accuracy: 0.0529\n",
      "Epoch 22/50\n",
      "305/305 [==============================] - 400s 1s/step - loss: 1.5774 - accuracy: 0.0530\n",
      "Epoch 23/50\n",
      "217/305 [====================>.........] - ETA: 1:56 - loss: 1.5868 - accuracy: 0.0540"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    [encoder_input, decoder_input],\n",
    "    decoder_output,\n",
    "    batch_size=32,\n",
    "    epochs=50\n",
    "    #,    validation_split=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
