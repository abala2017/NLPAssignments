{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model is based upon the SEQ2SEQ model used in the Keras blog\n",
    "## https://keras.io/examples/nlp/lstm_seq2seq/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\abala\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\users\\abala\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "c:\\users\\abala\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('preprocessedDataset.csv')\n",
    "df.head()\n",
    "df = df.dropna()\n",
    "df['speaker'] = df['speaker'].astype('str')\n",
    "df['response'] = df['response'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createSpeakerSet(text):\n",
    "    global promptSet\n",
    "    global promptDict\n",
    "    \n",
    "    text = str(text)\n",
    "    for word in text.split(' '):\n",
    "        if word in promptDict:\n",
    "            promptDict[word] = promptDict[word] + 1\n",
    "            if promptDict[word] > 2:\n",
    "                promptSet.add(word)\n",
    "        else:\n",
    "            promptDict[word] = 1\n",
    "        \n",
    "def createResponseSet(text):\n",
    "    global respnseSet\n",
    "    global reponseDict\n",
    "    \n",
    "    text = str(text)\n",
    "    for word in text.split(' '):\n",
    "        if word in responseDict:\n",
    "            responseDict[word] = responseDict[word] + 1\n",
    "            if responseDict[word] > 2:\n",
    "                responseSet.add(word)\n",
    "        else:\n",
    "            responseDict[word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "promptDict = {}\n",
    "responseDict = {}\n",
    "\n",
    "promptSet = set()\n",
    "responseSet = set()\n",
    "\n",
    "## add the end of the line word\n",
    "promptSet.add(\"<END>\")\n",
    "responseSet.add(\"<END>\")\n",
    "\n",
    "## add the word not in vocab word\n",
    "promptSet.add(\"<OTHER>\")\n",
    "responseSet.add(\"<OTHER>\")\n",
    "\n",
    "\n",
    "## create a set of the vocab for the speaker and the response\n",
    "_ = df['speaker'].apply(createSpeakerSet)\n",
    "_ = df['response'].apply(createResponseSet)\n",
    "\n",
    "## create the sorted vocabulary\n",
    "promptVocab = sorted(list(promptSet))\n",
    "responseVocab = sorted(list(promptSet))\n",
    "\n",
    "## get the size of the vocab\n",
    "promptVocabSize = len(promptVocab)\n",
    "responseVocabSize = len(responseVocab)\n",
    "\n",
    "## get the longest prompt and response\n",
    "#maxLenPrompt = max([len(str(txt)) for txt in list(df['speaker'])])\n",
    "maxLenPrompt = 50 + 1\n",
    "#maxLenResponse = max([len(str(txt)) for txt in list(df['response'])])\n",
    "maxLenResponse = 50 + 1\n",
    "\n",
    "\n",
    "## create the empty input and output vectors\n",
    "encoderInputSize = (len(df), maxLenPrompt, promptVocabSize)\n",
    "encoder_input = np.zeros(encoderInputSize, dtype = \"float32\")\n",
    "\n",
    "decoderInputSize = (len(df), maxLenResponse, responseVocabSize)\n",
    "decoder_input = np.zeros(decoderInputSize, dtype = \"float32\")\n",
    "\n",
    "decoder_output = np.zeros(decoderInputSize, dtype = \"float32\")\n",
    "\n",
    "## populate the empty input and output vectors\n",
    "inputText = list(df['speaker'])\n",
    "outputText = list(df['response'])\n",
    "\n",
    "for i, (i_t, o_t) in enumerate(zip(inputText, outputText)):\n",
    "    #print(inputText[i])\n",
    "    inputList = inputText[i].split(' ')\n",
    "    outputList = outputText[i].split(' ')\n",
    "    endInd = len(inputList)\n",
    "    if endInd > maxLenPrompt - 1:\n",
    "        endInd = maxLenPrompt - 1  \n",
    "    for x in range(endInd):\n",
    "        if inputList[x] in promptVocab:\n",
    "            ind = promptVocab.index(inputList[x])\n",
    "        else:\n",
    "            ind = promptVocab.index(\"<OTHER>\")\n",
    "        encoder_input[i][x][ind] = 1.0\n",
    "    encoder_input[i][x+1][promptVocab.index(\"<END>\")] = 1.0\n",
    "    endInd = len(outputList)\n",
    "    if endInd > maxLenResponse - 1:\n",
    "        endInd = maxLenResponse - 1\n",
    "    for x in range(endInd):\n",
    "        if outputList[x] in responseVocab:\n",
    "            ind = responseVocab.index(outputList[x])\n",
    "        else:\n",
    "            ind = responseVocab.index(\"<OTHER>\")\n",
    "        decoder_input[i][x][ind] = 1.0\n",
    "        if i >=1:\n",
    "            decoder_output[i][x-1][ind] = 1.0\n",
    "    decoder_input[i][x+1][responseVocab.index(\"<END>\")] = 1.0\n",
    "    decoder_output[i][x][responseVocab.index(\"<END>\")] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = keras.Input(shape = (None, promptVocabSize))\n",
    "encoder = keras.layers.LSTM(256, return_state = True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "decoder_inputs = keras.Input(shape = (None, responseVocabSize))\n",
    "\n",
    "decoder_lstm = keras.layers.LSTM(256, return_sequences = True, return_state = True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state = encoder_states)\n",
    "decoder_dense = keras.layers.Dense(responseVocabSize, activation = \"softmax\")\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "305/305 [==============================] - 363s 1s/step - loss: 1.5900 - accuracy: 0.0520\n",
      "Epoch 2/5\n",
      "305/305 [==============================] - 359s 1s/step - loss: 1.5859 - accuracy: 0.0521\n",
      "Epoch 3/5\n",
      "305/305 [==============================] - 374s 1s/step - loss: 1.5842 - accuracy: 0.0521\n",
      "Epoch 4/5\n",
      "305/305 [==============================] - 383s 1s/step - loss: 1.5841 - accuracy: 0.0521\n",
      "Epoch 5/5\n",
      "305/305 [==============================] - 446s 1s/step - loss: 1.5834 - accuracy: 0.0521\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x261cf06a2b0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    [encoder_input, decoder_input],\n",
    "    decoder_output,\n",
    "    batch_size=32,\n",
    "    epochs=5\n",
    "    #,    validation_split=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: seq2seq\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: seq2seq\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"seq2seq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"seq2seq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = model.input[0]\n",
    "encoder_outputs, state_h_enc, state_c_enc = model.layers[2].output\n",
    "encoder_states = [state_h_enc, state_c_enc]\n",
    "encoder_model = keras.Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_inputs = model.input[1]\n",
    "decoder_state_input_h = keras.Input(shape=(256,))\n",
    "decoder_state_input_c = keras.Input(shape=(256,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_lstm = model.layers[3]\n",
    "decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs\n",
    ")\n",
    "decoder_states = [state_h_dec, state_c_dec]\n",
    "decoder_dense = model.layers[4]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = keras.Model(\n",
    "    [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(input_seq):\n",
    "    states_val = encoder_model.predict(input_seq)\n",
    "    target_seq = np.zeros((1, 1, responseVocabSize))\n",
    "    target_seq[0, 0, 0] = 1.0 ## ignore the first word\n",
    "    \n",
    "    stop = False\n",
    "    sent = \"\"\n",
    "    while(stop == False):\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_val)\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_word = responseVocab[sampled_token_index]\n",
    "        sent = sent + sampled_word + \" \"\n",
    "        if sampled_word == '<END>' or len(sent.split(\" \")) > maxLenResponse:\n",
    "            stop = True\n",
    "        target_seq = np.zeros((1, 1, responseVocabSize))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.0\n",
    "        \n",
    "        states_val = [h,c]\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(text):\n",
    "    encoder_input = np.zeros((1, maxLenPrompt, promptVocabSize), dtype = \"float32\")\n",
    "    endInd = len(text.split(\" \"))\n",
    "    if endInd > maxLenPrompt - 1:\n",
    "        endInd = maxLenPrompt - 1  \n",
    "    for x in range(endInd):\n",
    "        if inputList[x] in promptVocab:\n",
    "            ind = promptVocab.index(inputList[x])\n",
    "        else:\n",
    "            ind = promptVocab.index(\"<OTHER>\")\n",
    "        encoder_input[0][x][ind] = 1.0\n",
    "    encoder_input[0][x+1][promptVocab.index(\"<END>\")] = 1.0\n",
    "    return encoder_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove stage directions which are typically in parenthesis (like this)\n",
    "def preprocess(text, isInput = True):\n",
    "    \n",
    "    ## Remove stage directions which are typically in parenthesis (like this)\n",
    "    text = re.sub(r'\\([^)]*\\)', '', str(text))\n",
    "    \n",
    "    ## Remove capital letters\n",
    "    text = text.lower()\n",
    "    \n",
    "    ## Remove contractions\n",
    "    contractions = re.findall(\"[']\", text)\n",
    "    for i in contractions:\n",
    "        text = text.replace(i,\"\")\n",
    "        \n",
    "    #replace multiple punctuation with single\n",
    "    repeatpunctuations = re.findall('[.,!?]{2,}',text)\n",
    "    for repeatpunctuation in repeatpunctuations:\n",
    "        text = text.replace(repeatpunctuation, repeatpunctuation[0])\n",
    "    \n",
    "    ## add spaces between last word and punctuation\n",
    "    puncs = re.findall('[.!?,]', text)\n",
    "    for i in puncs:\n",
    "        text = text.replace(i,\" \"+i[0]+\" \")\n",
    "        \n",
    "    ## remove all punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "        \n",
    "    ## remove multiple spaces and replace with just one\n",
    "    text =  re.sub(' +', ' ', text)\n",
    "    \n",
    "    ## remove trailing and leading spaces\n",
    "    text = text.strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addToCsv(lastText, nText):\n",
    "    df = pd.read_csv('dataset.csv')\n",
    "    df.loc[len(df.index)] = [lastText, nText]\n",
    "    df.to_csv('dataset'+ name +'.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello my name is Sheldon enter your name (Enter 'help' to change responses when in the bot): Arjun\n",
      "Hello Sheldon\n",
      "Sheldon: i believe leonard <END>\n",
      "How are you\n",
      "Sheldon: i do let <END>\n"
     ]
    }
   ],
   "source": [
    "isOn = True\n",
    "name = input(\"Hello my name is Sheldon enter your name (Enter 'help' to change responses when in the bot): \")\n",
    "lastText = ''\n",
    "while(isOn):\n",
    "    text = input(\"\")\n",
    "    if(text == 'help'):\n",
    "        nText = input(\"How should I have responded: \")\n",
    "        addToCsv(lastText, nText, name)\n",
    "    encoded = encode(preprocess(text))\n",
    "    output = decode(encoded)\n",
    "    print(\"Sheldon: \" + output)\n",
    "    lastText = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
