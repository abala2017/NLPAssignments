{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize ## import the tokenizer\n",
    "from nltk.corpus import stopwords ## import the stopwords\n",
    "from nltk.stem import WordNetLemmatizer ## import the lemmatizer\n",
    "from random import seed ## import the seeds for the random\n",
    "from random import randint ## import the random\n",
    "seed(42) ## set the seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lexical diversity is 0.15\n"
     ]
    }
   ],
   "source": [
    "# 2\n",
    "f = open(\"anat19.txt\", \"r\") ## open the corpus file\n",
    "raw_text = f.read() ## read the corpus in\n",
    "tokens = word_tokenize(raw_text) ## tokenize the corpus\n",
    "unique_tokens = set(tokens) ## get the unique tokens\n",
    "lexical_diversity = len(unique_tokens) / len(tokens) ## get the lexical diveristy by dividing unique / total\n",
    "print(\"The lexical diversity is %.2f\" % (lexical_diversity)) ## print out results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3\n",
    "def process_raw_text(raw_text):\n",
    "    # a\n",
    "    lower_text = raw_text.lower() ## lower the text\n",
    "    tokens = word_tokenize(lower_text) ## tokenize the text\n",
    "    tokens = [word for word in tokens if word.isalpha()] ## take out non-alphabetical tokens\n",
    "    stop_words = set(stopwords.words('english')) ## set the stopwords\n",
    "    tokens = [word for word in tokens if word not in stop_words] ## remove the stopwords from the token\n",
    "    tokens = [word for word in tokens if len(word) > 5] ## remove the words shorter than 5 letters\n",
    "    \n",
    "    # b\n",
    "    lemmatizer = WordNetLemmatizer() ## create the lemmatizer object\n",
    "    lemmas = [lemmatizer.lemmatize(word) for word in tokens] ## lemmatize the tokens\n",
    "    uniq_lemmas = set(lemmas) ## get the unique tokens\n",
    "    \n",
    "    # c\n",
    "    tags = nltk.pos_tag(uniq_lemmas) ## tag the parts of speech\n",
    "    print(\"The first 20 tagged items :\") ## print out the first 20 tags\n",
    "    print(tags[:20])\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    #d\n",
    "    nouns = [tag[0] for tag in tags if tag[1][:2] == \"NN\"] ## take out all the non-nouns\n",
    "\n",
    "    #e\n",
    "    print(\"The number of tokens is \" + str(len(tokens))) ## print the number of tokens\n",
    "    print(\"The number of nouns is \" + str(len(nouns))) ## print the number of nouns\n",
    "    \n",
    "    #f\n",
    "    return tokens,nouns ## return tokens and nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first 20 tagged items :\n",
      "[('toothpaste', 'NN'), ('diastolic', 'JJ'), ('consuming', 'VBG'), ('generating', 'VBG'), ('instrument', 'NN'), ('uncontrolled', 'JJ'), ('place', 'NN'), ('resonance', 'NN'), ('public', 'JJ'), ('generally', 'RB'), ('statistic', 'JJ'), ('inflow', 'JJ'), ('connection', 'NN'), ('absorption', 'NN'), ('emerging', 'VBG'), ('thyroxin', 'NN'), ('hydrogen', 'NN'), ('specifically', 'RB'), ('mesoderm', 'JJ'), ('cardiogenic', 'JJ')]\n",
      "\n",
      "\n",
      "The number of tokens is 7020\n",
      "The nymber of nouns is 740\n"
     ]
    }
   ],
   "source": [
    "tokens, nouns = process_raw_text(raw_text) ## call the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most common words and their count : \n",
      "[('muscle', 75), ('contraction', 70), ('ventricle', 68), ('pressure', 43), ('condition', 36), ('increase', 33), ('stimulation', 33), ('septum', 32), ('include', 27), ('impulse', 27), ('calcium', 26), ('oxygen', 24), ('depolarization', 24), ('percent', 22), ('system', 22), ('conduction', 20), ('semilunar', 20), ('diastole', 19), ('complex', 19), ('tissue', 18), ('contractile', 18), ('activity', 17), ('contract', 16), ('chordae', 16), ('function', 16), ('myocardium', 16), ('tendineae', 16), ('period', 15), ('patient', 14), ('contractility', 13), ('exercise', 13), ('supply', 13), ('treatment', 13), ('membrane', 13), ('disease', 13), ('circulation', 13), ('preload', 13), ('sulcus', 12), ('trigger', 11), ('repolarization', 11), ('volume', 11), ('portion', 11), ('strength', 10), ('region', 10), ('failure', 10), ('cavity', 10), ('stretch', 10), ('mechanism', 10), ('sodium', 10), ('vessel', 10)]\n"
     ]
    }
   ],
   "source": [
    "# 4\n",
    "noun_count = {nouns[i] : tokens.count(nouns[i]) for i in range(len(nouns))} ## get the count of each noun\n",
    "sorted_count = sorted(noun_count.items(), key=lambda x:x[1], reverse = True) ## sort them by most common\n",
    "most_common = sorted_count[:50] ## get the first 50 common nouns\n",
    "print(\"The most common words and their count : \") ## print them out\n",
    "print(most_common)\n",
    "word_bank = [word[0] for word in most_common] ## get the words from the list of tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5\n",
    "def guessing_game(word_bank):\n",
    "    print(\"Let's play a word guessing game!\") ## print the starting dialouge\n",
    "    points = 5 ## set the points\n",
    "    lose = win = False ## set the win/lose conditions\n",
    "    word = word_bank[randint(0,49)] ## pick the word\n",
    "    guessed = [] ## letters guessed by user\n",
    "    while((not lose) and (not win)): ## make sure the user has not won or lost\n",
    "        print(\"\".join([letter if letter in guessed else \"-\" for letter in word])) ## print out the dashes\n",
    "        guess = input(\"Guess a letter: \") ## print the prompt and get the next letter\n",
    "        if(len(guess) != 1): ## validate the input\n",
    "            print(\"invalid input ಠ_ಠ\") ## complain if its not correct\n",
    "            continue ## restart the loop\n",
    "        if(guess in guessed): ## check if they guessed the letter already\n",
    "            print(\"already guessed (ง •̀_•́)ง\") ## complain\n",
    "            continue ## restart loop\n",
    "        guessed += guess ## add guess to the guessed letters\n",
    "        if(guess in word): ## check if the guessed letter is in the goal word\n",
    "            points = points + 1 ## if it is increase points\n",
    "            print(\"Right! Score is \" + str(points) + \" ヘ( ^o^)ノ＼(^_^ )\") ## congratulate\n",
    "        else:\n",
    "            points = points - 1 ## if not, decrease points\n",
    "            print(\"Sorry, wrong guess. Score is \" + str(points) + \" ¯\\_(ツ)_/¯\") ## print score and miss\n",
    "        win = set(word).issubset(set(guessed)) ## win condition met if all the letters have been guessed\n",
    "        if(points == 0): ## check if we reached 0 points\n",
    "            lose = True ## lose condition met if points = 0\n",
    "    if(win): ## if the player wins\n",
    "        print(\"You solved it!\") ## congratulate\n",
    "        print(\"Final Score: \" + str(points)) ## print final score\n",
    "        print(\"( ͡°( ͡° ͜ʖ( ͡° ͜ʖ ͡°)ʖ ͡°) ͡°)\") ## the crowd goes wild\n",
    "    else: ## if the player loses\n",
    "        print(\"Maybe next time o(╥﹏╥)o\") ## help them deal with the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's play a word guessing game!\n",
      "-------\n",
      "Guess a letter: a\n",
      "Right! Score is 6 ヘ( ^o^)ノ＼(^_^ )\n",
      "----a--\n",
      "Guess a letter: m\n",
      "Sorry, wrong guess. Score is 5 ¯\\_(ツ)_/¯\n",
      "----a--\n",
      "Guess a letter: q\n",
      "Sorry, wrong guess. Score is 4 ¯\\_(ツ)_/¯\n",
      "----a--\n",
      "Guess a letter: e\n",
      "Right! Score is 5 ヘ( ^o^)ノ＼(^_^ )\n",
      "---ea-e\n",
      "Guess a letter: s\n",
      "Right! Score is 6 ヘ( ^o^)ノ＼(^_^ )\n",
      "--sease\n",
      "Guess a letter: d\n",
      "Right! Score is 7 ヘ( ^o^)ノ＼(^_^ )\n",
      "d-sease\n",
      "Guess a letter: i\n",
      "Right! Score is 8 ヘ( ^o^)ノ＼(^_^ )\n",
      "You solved it!\n",
      "Final Score: 8\n",
      "( ͡°( ͡° ͜ʖ( ͡° ͜ʖ ͡°)ʖ ͡°) ͡°)\n"
     ]
    }
   ],
   "source": [
    "guessing_game(word_bank) ## play the game"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
