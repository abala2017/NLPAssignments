{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\abala\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\users\\abala\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "c:\\users\\abala\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models, preprocessing\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-8dc39d4757fb>:48: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_train = np.array(x_train)\n",
      "<ipython-input-2-8dc39d4757fb>:52: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_test = np.array(x_test)\n"
     ]
    }
   ],
   "source": [
    "toInt = {'Negative': 0, 'Neutral': 1, 'Positive':2}\n",
    "toString = {0: 'Negative', 1: 'Neutral', 2: 'Positive'}\n",
    "\n",
    "## load the tweets\n",
    "df = pd.read_csv('tweets_train.csv', encoding = \"ISO-8859-1\")\n",
    "df_test = pd.read_csv('tweets_test.csv', encoding = \"ISO-8859-1\")\n",
    "\n",
    "# take out the empty tweets\n",
    "df = df.loc[df['OriginalTweet'].str.len() >= 1]\n",
    "df_test = df_test.loc[df_test['OriginalTweet'].str.len() >= 1]\n",
    "\n",
    "## separate the x and the y\n",
    "x_train, y_train = list(df['OriginalTweet']), list(df['Sentiment'])\n",
    "x_test, y_test = list(df['OriginalTweet']), list(df['Sentiment'])\n",
    "\n",
    "## convert the y to categorical numbers\n",
    "ny_train = []\n",
    "for label in y_train:\n",
    "    ny_train.append(toInt[label])\n",
    "\n",
    "ny_test = []\n",
    "for label in y_test:\n",
    "    ny_test.append(toInt[label])\n",
    "\n",
    "y_train = ny_train\n",
    "y_test = ny_test\n",
    "\n",
    "## convert to one-hot \n",
    "y_train = np.array(y_train)\n",
    "ny_train = np.zeros((y_train.size, y_train.max() + 1))\n",
    "ny_train[np.arange(y_train.size), y_train] = 1\n",
    "y_train = ny_train\n",
    "\n",
    "y_test = np.array(y_test)\n",
    "ny_test = np.zeros((y_test.size, y_test.max() + 1))\n",
    "ny_test[np.arange(y_test.size), y_test] = 1\n",
    "y_test = ny_test\n",
    "\n",
    "## create the tokenizer and train\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "\n",
    "## tokenize the inputs\n",
    "maxLen = max([len(s.split()) for s in x_train])\n",
    "vocabSize = len(tokenizer.word_index) + 1\n",
    "\n",
    "x_train = tokenizer.texts_to_sequences(x_train)\n",
    "x_train = np.array(x_train)\n",
    "x_train = preprocessing.sequence.pad_sequences(x_train, maxlen = maxLen).astype(np.int32)\n",
    "\n",
    "x_test = tokenizer.texts_to_sequences(x_test)\n",
    "x_test = np.array(x_test)\n",
    "x_test = preprocessing.sequence.pad_sequences(x_test, maxlen = maxLen).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 32)          1140416   \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      (None, 32)                2080      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,142,595\n",
      "Trainable params: 1,142,595\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "max_features = 10000\n",
    "model = models.Sequential()\n",
    "model.add(layers.Embedding(vocabSize, 32))\n",
    "model.add(layers.SimpleRNN(32))\n",
    "model.add(layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1286/1286 [==============================] - 69s 52ms/step - loss: 0.8527 - accuracy: 0.5911\n",
      "Epoch 2/10\n",
      "1286/1286 [==============================] - 62s 48ms/step - loss: 0.4140 - accuracy: 0.8550\n",
      "Epoch 3/10\n",
      "1286/1286 [==============================] - 66s 51ms/step - loss: 0.2065 - accuracy: 0.9341\n",
      "Epoch 4/10\n",
      "1286/1286 [==============================] - 74s 57ms/step - loss: 0.0967 - accuracy: 0.9707\n",
      "Epoch 5/10\n",
      "1286/1286 [==============================] - 72s 56ms/step - loss: 0.0567 - accuracy: 0.9829\n",
      "Epoch 6/10\n",
      "1286/1286 [==============================] - 66s 51ms/step - loss: 0.0429 - accuracy: 0.9873\n",
      "Epoch 7/10\n",
      "1286/1286 [==============================] - 60s 46ms/step - loss: 0.0349 - accuracy: 0.9891\n",
      "Epoch 8/10\n",
      "1286/1286 [==============================] - 59s 46ms/step - loss: 0.0322 - accuracy: 0.9908\n",
      "Epoch 9/10\n",
      "1286/1286 [==============================] - 68s 53ms/step - loss: 0.0515 - accuracy: 0.9843\n",
      "Epoch 10/10\n",
      "1286/1286 [==============================] - 60s 47ms/step - loss: 0.0217 - accuracy: 0.9940\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a3132538b0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1286/1286 [==============================] - 12s 9ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     15396\n",
      "           1       1.00      1.00      1.00      7699\n",
      "           2       1.00      1.00      1.00     18044\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     41139\n",
      "   macro avg       1.00      1.00      1.00     41139\n",
      "weighted avg       1.00      1.00      1.00     41139\n",
      " samples avg       1.00      1.00      1.00     41139\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(x_test)\n",
    "pred = (pred == pred.max(axis=1)[:,None]).astype(int)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, None, 32)          1140416   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 32)                8320      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,148,835\n",
      "Trainable params: 1,148,835\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "max_features = 10000\n",
    "model = models.Sequential()\n",
    "model.add(layers.Embedding(vocabSize, 32))\n",
    "model.add(layers.LSTM(32))\n",
    "model.add(layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1286/1286 [==============================] - 104s 78ms/step - loss: 0.6256 - accuracy: 0.7396\n",
      "Epoch 2/10\n",
      "1286/1286 [==============================] - 104s 81ms/step - loss: 0.2934 - accuracy: 0.9071\n",
      "Epoch 3/10\n",
      "1286/1286 [==============================] - 103s 80ms/step - loss: 0.2026 - accuracy: 0.9386\n",
      "Epoch 4/10\n",
      "1286/1286 [==============================] - 102s 79ms/step - loss: 0.1533 - accuracy: 0.9534\n",
      "Epoch 5/10\n",
      "1286/1286 [==============================] - 102s 79ms/step - loss: 0.1187 - accuracy: 0.9626\n",
      "Epoch 6/10\n",
      "1286/1286 [==============================] - 102s 80ms/step - loss: 0.0948 - accuracy: 0.9692\n",
      "Epoch 7/10\n",
      "1286/1286 [==============================] - 102s 79ms/step - loss: 0.0785 - accuracy: 0.9736\n",
      "Epoch 8/10\n",
      "1286/1286 [==============================] - 102s 79ms/step - loss: 0.0653 - accuracy: 0.9783\n",
      "Epoch 9/10\n",
      "1286/1286 [==============================] - 103s 80ms/step - loss: 0.0524 - accuracy: 0.9826\n",
      "Epoch 10/10\n",
      "1138/1286 [=========================>....] - ETA: 11s - loss: 0.0388 - accuracy: 0.9878"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x_test)\n",
    "pred = (pred == pred.max(axis=1)[:,None]).astype(int)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
